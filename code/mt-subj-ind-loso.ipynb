{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing libraries and libcudnn8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:40:30.562782Z",
     "iopub.status.busy": "2024-11-25T02:40:30.562122Z",
     "iopub.status.idle": "2024-11-25T02:42:49.887785Z",
     "shell.execute_reply": "2024-11-25T02:42:49.886435Z",
     "shell.execute_reply.started": "2024-11-25T02:40:30.562695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## only with GPU\n",
    "\n",
    "import os\n",
    "\n",
    "FILEID = \"1h4FWB5fw7sBDCSM-EENK1UadqKSCqg24\"\n",
    "\n",
    "contents = os.listdir(os.getcwd())\n",
    "\n",
    "if 'MI_EEG_ClassMeth' not in contents:\n",
    "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n",
    "    !unzip MI_EEG_ClassMeth.zip\n",
    "else:\n",
    "    print(\"MI_EEG_ClassMeth already downloaded!\")\n",
    "\n",
    "!apt-get install --allow-change-held-packages libcudnn8=8.1.1.33-1+cuda11.2 -y\n",
    "!pip install mne\n",
    "!pip install pickle5\n",
    "!pip install gcpds.utils\n",
    "!pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:42:52.597987Z",
     "iopub.status.busy": "2024-11-25T02:42:52.597666Z",
     "iopub.status.idle": "2024-11-25T02:42:58.071859Z",
     "shell.execute_reply": "2024-11-25T02:42:58.070737Z",
     "shell.execute_reply.started": "2024-11-25T02:42:52.597962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FILEID = \"1Xre9ciaaP__8BJ4zhgJFbLCoJb_qwVNL\"\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O data_new.npz && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005353,
     "end_time": "2022-10-22T21:59:26.046417",
     "exception": false,
     "start_time": "2022-10-22T21:59:26.041064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:03.131644Z",
     "iopub.status.busy": "2024-11-25T02:43:03.131315Z",
     "iopub.status.idle": "2024-11-25T02:43:09.747062Z",
     "shell.execute_reply": "2024-11-25T02:43:09.746073Z",
     "shell.execute_reply.started": "2024-11-25T02:43:03.131619Z"
    },
    "papermill": {
     "duration": 10.438951,
     "end_time": "2022-10-22T22:02:26.565555",
     "exception": false,
     "start_time": "2022-10-22T22:02:16.126604",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# freq filter \n",
    "from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n",
    "\n",
    "#EEG montage\n",
    "from gcpds.utils.mne_handler import get_best_montage\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import pickle5 as pickle\n",
    "import warnings\n",
    "import mne\n",
    "from time import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# tensorlfow \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, AveragePooling2D, BatchNormalization, Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "# scikeras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:12.043478Z",
     "iopub.status.busy": "2024-11-25T02:43:12.042052Z",
     "iopub.status.idle": "2024-11-25T02:43:12.047792Z",
     "shell.execute_reply": "2024-11-25T02:43:12.046792Z",
     "shell.execute_reply.started": "2024-11-25T02:43:12.043430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(np.argmax(y_true, axis = 1),np.argmax(y_pred, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:14.071600Z",
     "iopub.status.busy": "2024-11-25T02:43:14.071258Z",
     "iopub.status.idle": "2024-11-25T02:43:14.083943Z",
     "shell.execute_reply": "2024-11-25T02:43:14.083229Z",
     "shell.execute_reply.started": "2024-11-25T02:43:14.071571Z"
    },
    "papermill": {
     "duration": 2.730715,
     "end_time": "2022-10-22T22:02:29.329591",
     "exception": false,
     "start_time": "2022-10-22T22:02:26.598876",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_PAIN(db,sbj,f_bank,vwt,new_fs):\n",
    "\n",
    "    channels_names = np.array(['Fp1','Fp2',\n",
    "                      'F3','F4','C3','C4','P3','P4','O1','O2','F7','F8',\n",
    "                      'T7','T8','P7','P8','Fz','Cz','Pz','Oz',\n",
    "                      'FC1','FC2','CP1','CP2','FC5','FC6','CP5','CP6',\n",
    "                      'TP9','TP10','LE','RE','P1','P2','C1','C2',\n",
    "                      'FT9','FT10','AF3','AF4','FC3','FC4','CP3','CP4','PO3','PO4',\n",
    "                      'F5','F6','C5','C6','P5','P6','PO9','Iz','FT7','FT8',\n",
    "                      'TP7','TP8','PO7','PO8','Fpz','PO10','CPz','POz',\n",
    "                      'Ne','Ma','Ext','ECG'])\n",
    "    \n",
    "    with open('{}BMOP_Motor_S{}.pkl'.format(db,'0' + str(sbj) if sbj < 10 else sbj), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    X = data['X']  # trials, channels, time\n",
    "    y = data['y']\n",
    "    sex = data['sex'].ravel()\n",
    "    age = data['age'].ravel()\n",
    "    fs = float(data['fs'])\n",
    "    \n",
    "    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "    \n",
    "    #Read electrode positions to load the best standard montage-MNE\n",
    "    best_montages = get_best_montage(channels_names)\n",
    "    montage = best_montages.iloc[0]['montage']\n",
    "    no_channels = np.array(best_montages.iloc[0]['missings channels'])\n",
    "    channels_to_remove = np.array([np.argwhere(channels_names==no)[0] for no in no_channels])[:,0]\n",
    "\n",
    "    #Delete the missing channels the original array respecting the positions\n",
    "    channels_names = np.delete(channels_names, channels_to_remove)\n",
    "    X = np.delete(X, channels_to_remove, axis=1)\n",
    "\n",
    "    #Number channels does not match with the dimension of X, \n",
    "    #thus the last channel is discarded because it has weird amplitudes\n",
    "    X = X[:,:-1,:]\n",
    "\n",
    "    info = mne.create_info(list(channels_names), sfreq=fs, ch_types=\"eeg\")\n",
    "    info.set_montage(montage)\n",
    "    info\n",
    "\n",
    "    event_id = {\n",
    "        'pain/high':2,\n",
    "        'resting':3,\n",
    "        }\n",
    "\n",
    "    events = [[i, 1, cls[0]] for i, cls in enumerate(y)]\n",
    "    tmin = 0\n",
    "\n",
    "    epochs = mne.EpochsArray(X, info, events=events, tmin=tmin, event_id=event_id)\n",
    "    X = epochs.get_data()\n",
    "    y = y-2\n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "                             \n",
    "    #Resampling\n",
    "    if new_fs != fs:\n",
    "        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "    return X,y,age,sex,fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model (Gaussian functional conectivity network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:17.303772Z",
     "iopub.status.busy": "2024-11-25T02:43:17.303424Z",
     "iopub.status.idle": "2024-11-25T02:43:17.324074Z",
     "shell.execute_reply": "2024-11-25T02:43:17.323203Z",
     "shell.execute_reply.started": "2024-11-25T02:43:17.303743Z"
    },
    "papermill": {
     "duration": 4.643402,
     "end_time": "2022-10-22T22:02:34.006275",
     "exception": false,
     "start_time": "2022-10-22T22:02:29.362873",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GFC(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.gammad = self.add_weight(name = 'gammad',\n",
    "                                shape = (),\n",
    "                                initializer = 'zeros',\n",
    "                                trainable = True)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X): \n",
    "        X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n",
    "        R = tf.reduce_sum(tf.math.multiply(X, X), axis = -1, keepdims = True) #(N, F, C, 1)\n",
    "        D  = R - 2*tf.matmul(X, X, transpose_b = True) + tf.transpose(R, perm = (0, 1, 3, 2)) #(N, F, C, C)\n",
    "\n",
    "        ones = tf.ones_like(D[0,0,...]) #(C, C)\n",
    "        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n",
    "        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n",
    "        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n",
    "        triu = tf.expand_dims(tf.boolean_mask(D, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n",
    "        sigma = tfp.stats.percentile(tf.math.sqrt(triu), 50, axis = 2, keepdims = True) #(N, F, 1, 1)\n",
    "\n",
    "        A = tf.math.exp(-1/(2*tf.pow(10., self.gammad)*tf.math.square(sigma))*D) #(N, F, C, C)\n",
    "        A.set_shape(D.shape)\n",
    "        return A\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        N, C, T, F = batch_input_shape.as_list()\n",
    "        return tf.TensorShape([N, F, C, C])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "\n",
    "\n",
    "class get_triu(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X): \n",
    "        N, F, C, C = X.shape\n",
    "        ones = tf.ones_like(X[0,0,...]) #(C, C)\n",
    "        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n",
    "        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n",
    "        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n",
    "        triu = tf.expand_dims(tf.boolean_mask(X, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n",
    "\n",
    "        triu.set_shape([N,F,int(C*(C-1)/2),1])\n",
    "        return triu\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        N, F, C, C = batch_input_shape.as_list()\n",
    "        return tf.TensorShape([N, F, int(C*(C-1)/2),1])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "    \n",
    "    \n",
    "def GFC_triu_net_avg(nb_classes: int,\n",
    "          Chans: int,\n",
    "          Samples: int,\n",
    "          l1: int = 0, \n",
    "          l2: int = 0, \n",
    "          dropoutRate: float = 0.5,\n",
    "          filters: int = 1, \n",
    "          maxnorm: float = 2.0,\n",
    "          maxnorm_last_layer: float = 0.5,\n",
    "          kernel_time_1: int = 20,\n",
    "          strid_filter_time_1: int = 1,\n",
    "          bias_spatial: bool = False) -> Model:\n",
    "\n",
    "\n",
    "    input_main   = Input((Chans, Samples, 1),name='Input')                    \n",
    "    \n",
    "    block        = Conv2D(filters,(1,kernel_time_1),strides=(1,strid_filter_time_1),\n",
    "                            use_bias=bias_spatial,\n",
    "                            kernel_constraint = max_norm(maxnorm, axis=(0,1,2))\n",
    "                            )(input_main)\n",
    "    \n",
    "    block        = BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n",
    "\n",
    "    block        = Activation('elu')(block)      \n",
    "    \n",
    "    block        = GFC()(block)\n",
    "\n",
    "    block        = get_triu()(block)\n",
    "\n",
    "    block        = AveragePooling2D(pool_size=(block.shape[1],1),strides=(1,1))(block)\n",
    "    \n",
    "    block        = BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n",
    "\n",
    "    block        = Activation('elu')(block) \n",
    "    \n",
    "    block        = Flatten()(block)    \n",
    "\n",
    "    block        = Dropout(dropoutRate)(block) \n",
    "\n",
    "    block        = Dense(nb_classes, kernel_regularizer=L1L2(l1=l1,l2=l2),name='logits',\n",
    "                              kernel_constraint = max_norm(maxnorm_last_layer)\n",
    "                              )(block)\n",
    "\n",
    "    softmax      = Activation('softmax',name='output')(block)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model (EEGNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:18.889794Z",
     "iopub.status.busy": "2024-11-25T02:43:18.889446Z",
     "iopub.status.idle": "2024-11-25T02:43:18.900500Z",
     "shell.execute_reply": "2024-11-25T02:43:18.899539Z",
     "shell.execute_reply.started": "2024-11-25T02:43:18.889765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "def EEGNet(nb_classes, Chans = 64, Samples = 128,\n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8,\n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   name='Conv2D_1',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n",
    "                                   name='Depth_wise_Conv2D_1',\n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   name='Separable_Conv2D_1',\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "\n",
    "    dense        = Dense(nb_classes, name = 'output',\n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'out_activation')(dense)\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T22:02:34.07466Z",
     "iopub.status.busy": "2022-10-22T22:02:34.074032Z",
     "iopub.status.idle": "2022-10-22T22:02:34.086988Z",
     "shell.execute_reply": "2022-10-22T22:02:34.086008Z"
    },
    "papermill": {
     "duration": 0.049558,
     "end_time": "2022-10-22T22:02:34.089324",
     "exception": false,
     "start_time": "2022-10-22T22:02:34.039766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:29.569419Z",
     "iopub.status.busy": "2024-11-25T02:43:29.568775Z",
     "iopub.status.idle": "2024-11-25T02:43:29.574217Z",
     "shell.execute_reply": "2024-11-25T02:43:29.573145Z",
     "shell.execute_reply.started": "2024-11-25T02:43:29.569388Z"
    },
    "papermill": {
     "duration": 0.048584,
     "end_time": "2022-10-22T22:02:34.171415",
     "exception": false,
     "start_time": "2022-10-22T22:02:34.122831",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "seed=23\n",
    "folds=5\n",
    "epochs_train = 500\n",
    "\n",
    "model_name = f'GFC'\n",
    "\n",
    "save_folder = os.path.join('Gender_Based_Exp', 'Gender_Based_Exp')\n",
    "\n",
    "n_subjects = 51\n",
    "\n",
    "PATH = f'{os. getcwd()}/{save_folder}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:31.514742Z",
     "iopub.status.busy": "2024-11-25T02:43:31.513745Z",
     "iopub.status.idle": "2024-11-25T02:43:31.533436Z",
     "shell.execute_reply": "2024-11-25T02:43:31.532483Z",
     "shell.execute_reply.started": "2024-11-25T02:43:31.514706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loaded_data = np.load('data_new.npz')\n",
    "\n",
    "female = 0\n",
    "male = 1\n",
    "\n",
    "# Convert back to DataFrame\n",
    "loaded_df = pd.DataFrame({key: loaded_data[key] for key in loaded_data.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:43:32.742728Z",
     "iopub.status.busy": "2024-11-25T02:43:32.742273Z",
     "iopub.status.idle": "2024-11-25T02:43:32.766571Z",
     "shell.execute_reply": "2024-11-25T02:43:32.765470Z",
     "shell.execute_reply.started": "2024-11-25T02:43:32.742688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "good_females = loaded_df[loaded_df['sex'] == female][loaded_df['gfcACC'] >= 0.85]['Sbj'].to_numpy()\n",
    "good_males = loaded_df[loaded_df['sex'] == male][loaded_df['gfcACC'] >= 0.85]['Sbj'].to_numpy()\n",
    "\n",
    "training_details = {'Females': {'Subjects': good_females}, 'Males': {'Subjects': good_males}}\n",
    "training_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T22:02:35.565905Z",
     "iopub.status.busy": "2022-10-22T22:02:35.565531Z",
     "iopub.status.idle": "2022-10-22T22:02:35.582215Z",
     "shell.execute_reply": "2022-10-22T22:02:35.581284Z"
    },
    "papermill": {
     "duration": 0.051828,
     "end_time": "2022-10-22T22:02:35.58406",
     "exception": false,
     "start_time": "2022-10-22T22:02:35.532232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T11:06:32.904302Z",
     "iopub.status.busy": "2024-11-24T11:06:32.903962Z"
    },
    "papermill": {
     "duration": 16769.446163,
     "end_time": "2022-10-23T02:42:05.14864",
     "exception": false,
     "start_time": "2022-10-22T22:02:35.702477",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "print(\"Starting experiment...\\n\")\n",
    "\n",
    "db = '../input/brain-mediators-of-pain-motor/'\n",
    "\n",
    "load_args = dict(db = db,\n",
    "            f_bank = np.asarray([[4., 60.]]),\n",
    "            vwt = np.asarray([[0.5,2.5]]),\n",
    "            new_fs = 500.0)\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "t=time()\n",
    "genders = ['Females', 'Males']\n",
    "\n",
    "models = ['KCSFCnet', 'EEGNet']\n",
    "\n",
    "for model_name in models:\n",
    "    for gender in genders:\n",
    "        print(\"------------------------------------------------------------------------------------------\\n\")\n",
    "        print(f\"{' '*25}{model_name} - {gender} starting...\")\n",
    "        print(\"------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        gender_subs = training_details[gender][\"Subjects\"]\n",
    "        \n",
    "        training_details[gender][\"Groups\"] = []\n",
    "        \n",
    "        g = 0\n",
    "        \n",
    "        for sbj in gender_subs:\n",
    "            print(f\"Loading subject: {int(sbj)}\\n\")\n",
    "            load_args['sbj'] = int(sbj) \n",
    "    \n",
    "            if (sbj == gender_subs[0]):\n",
    "                X_train, Y_train, _, sex, fs = load_PAIN(**load_args)\n",
    "                g+=1\n",
    "                training_details[gender][\"Groups\"] += [g] * len(X_train)\n",
    "            else:\n",
    "                X_train_, Y_train_, _, sex, fs = load_PAIN(**load_args)\n",
    "                X_train = np.concatenate((X_train, X_train_), axis = 0)\n",
    "                Y_train = np.concatenate((Y_train, Y_train_), axis = 0)\n",
    "                \n",
    "                g+=1\n",
    "                training_details[gender][\"Groups\"] += [g] * len(X_train_)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        Y_train = tf.keras.utils.to_categorical(Y_train,num_classes=num_class)\n",
    "\n",
    "        if model_name == 'KCSFCnet':\n",
    "            # ----build model\n",
    "            clf = KerasClassifier(\n",
    "            GFC_triu_net_avg,\n",
    "            random_state=seed,\n",
    "    \n",
    "            # ----model hyperparameters\n",
    "            nb_classes=num_class, \n",
    "            Chans = X_train.shape[1], \n",
    "            Samples = X_train.shape[2],\n",
    "            dropoutRate=0.5,\n",
    "            l1 = 1e-3, l2 = 1e-3,\n",
    "            filters=2, maxnorm=2.0,maxnorm_last_layer=0.5,\n",
    "            kernel_time_1=int(fs*0.1),strid_filter_time_1= 1,\n",
    "            bias_spatial = False,\n",
    "    \n",
    "            # ----model config\n",
    "            verbose=0,\n",
    "            batch_size=500, #full batch        \n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            optimizer=\"adam\",\n",
    "            optimizer_learning__rate=0.1,\n",
    "            metrics = ['accuracy'],\n",
    "            epochs = epochs_train)\n",
    "            \n",
    "            # ----search params\n",
    "            param_grid =  {\n",
    "                'filters':[2, 4, 8],\n",
    "                'kernel_time_1':[int(fs*0.1), int(fs*0.25), int(fs*0.5)],\n",
    "                }\n",
    "            \n",
    "        elif model_name == 'EEGNet':\n",
    "            # ----build model\n",
    "            clf = KerasClassifier(\n",
    "                    EEGNet,\n",
    "                    random_state=seed,\n",
    "                    # ----model hyperparameters\n",
    "                    nb_classes=num_class, \n",
    "                    Chans = X_train.shape[1], \n",
    "                    Samples = X_train.shape[2],\n",
    "                    dropoutRate = 0.5,\n",
    "                    kernLength = int(fs/2),\n",
    "                    F1 = 8, D = 2, F2 = 16,\n",
    "                    # ----model config\n",
    "                    verbose=0,\n",
    "                    batch_size=500, #full batch        \n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    optimizer=\"adam\",\n",
    "                    optimizer_learning__rate=0.1,\n",
    "                    metrics = ['accuracy'],\n",
    "                    epochs = epochs_train\n",
    "                )\n",
    "        \n",
    "                # ----search params\n",
    "            param_grid =  {'F1':[4, 8], 'kernLength':[int(fs/4), int(fs/2)]}\n",
    "        \n",
    "        logo = LeaveOneGroupOut()\n",
    "    \n",
    "        # ----Gridsearch\n",
    "        scoring = {\"AUC\": 'roc_auc', \"Accuracy\": make_scorer(accuracy_score),'Kappa':make_scorer(kappa)}\n",
    "    \n",
    "        cv = GridSearchCV(clf,param_grid,cv=logo,\n",
    "                             verbose=0,n_jobs=1,\n",
    "                             scoring=scoring,\n",
    "                             refit=\"Accuracy\",\n",
    "                                )\n",
    "        # ----find best params with gridsearch\n",
    "        cv.fit(X = X_train, y = Y_train, groups = training_details[gender][\"Groups\"])\n",
    "    \n",
    "        # ----best score\n",
    "        print(f'{model_name} - {gender} ','Accuracy',cv.best_score_,'elapsed time',time()-t)\n",
    "        print('---------')\n",
    "    \n",
    "        cv.cv_results_['best_index_'] = cv.best_index_\n",
    "\n",
    "        full_path = os.path.join(os.getcwd(), f'{model_name}MotorLosoGenderL1L285', gender)\n",
    "\n",
    "        try:\n",
    "            os.makedirs(full_path)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        cv.best_estimator_.model_.save_weights(full_path + f'/{model_name}l1l285_{gender}_weights.h5')\n",
    "        with open(full_path + f'/{model_name}l1l285_{gender}.p','wb') as f:\n",
    "            pickle.dump(cv.cv_results_,f)     "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1645904,
     "sourceId": 2702213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1269900,
     "sourceId": 2702226,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4722020,
     "sourceId": 8014908,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30302,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
