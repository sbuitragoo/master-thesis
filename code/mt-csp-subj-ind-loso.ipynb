{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-25T00:09:38.263288Z",
     "iopub.status.busy": "2024-11-25T00:09:38.262828Z",
     "iopub.status.idle": "2024-11-25T00:10:06.734533Z",
     "shell.execute_reply": "2024-11-25T00:10:06.733134Z",
     "shell.execute_reply.started": "2024-11-25T00:09:38.263245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.8\n",
      "  Downloading scipy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting numpy<1.25.0,>=1.17.3 (from scipy==1.8)\n",
      "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading scipy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 1.4.17 requires scipy>=1.10.0, but you have scipy 1.8.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.8.0 which is incompatible.\n",
      "bayesian-optimization 1.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.24.4 which is incompatible.\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
      "featuretools 1.31.0 requires scipy>=1.10.0, but you have scipy 1.8.0 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.8.0 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.8.0 which is incompatible.\n",
      "kaggle-environments 1.14.15 requires scipy>=1.11.2, but you have scipy 1.8.0 which is incompatible.\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "mne 1.8.0 requires scipy>=1.9, but you have scipy 1.8.0 which is incompatible.\n",
      "scikit-image 0.23.2 requires scipy>=1.9, but you have scipy 1.8.0 which is incompatible.\n",
      "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.8.0 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.8.0 which is incompatible.\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
      "woodwork 0.31.0 requires scipy>=1.10.0, but you have scipy 1.8.0 which is incompatible.\n",
      "xarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.4 scipy-1.8.0\n",
      "Cloning into 'MI-EEG-ClassMeth'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 37 (delta 9), reused 15 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (37/37), 83.24 KiB | 2.68 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scipy==1.8\n",
    "!git clone https://github.com/Marcos-L/MI-EEG-ClassMeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:21.703992Z",
     "iopub.status.busy": "2024-11-25T00:10:21.703542Z",
     "iopub.status.idle": "2024-11-25T00:10:21.713531Z",
     "shell.execute_reply": "2024-11-25T00:10:21.712258Z",
     "shell.execute_reply.started": "2024-11-25T00:10:21.703947Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/MI-EEG-ClassMeth\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working/MI-EEG-ClassMeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:29.375492Z",
     "iopub.status.busy": "2024-11-25T00:10:29.375096Z",
     "iopub.status.idle": "2024-11-25T00:10:32.105175Z",
     "shell.execute_reply": "2024-11-25T00:10:32.104000Z",
     "shell.execute_reply.started": "2024-11-25T00:10:29.375453Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from MI_EEG_ClassMeth.MIfunctions import Window_band_CSP_eppoch, flatt, elastic_net_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:36.124943Z",
     "iopub.status.busy": "2024-11-25T00:10:36.123651Z",
     "iopub.status.idle": "2024-11-25T00:10:36.131973Z",
     "shell.execute_reply": "2024-11-25T00:10:36.130443Z",
     "shell.execute_reply.started": "2024-11-25T00:10:36.124895Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:38.218861Z",
     "iopub.status.busy": "2024-11-25T00:10:38.217195Z",
     "iopub.status.idle": "2024-11-25T00:10:38.245276Z",
     "shell.execute_reply": "2024-11-25T00:10:38.243467Z",
     "shell.execute_reply.started": "2024-11-25T00:10:38.218737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score, accuracy_score, \\\n",
    "                            f1_score, recall_score, precision_score, make_scorer\n",
    "from scipy.signal import freqz, filtfilt, resample\n",
    "from scipy.signal import butter as bw\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:43.779183Z",
     "iopub.status.busy": "2024-11-25T00:10:43.778507Z",
     "iopub.status.idle": "2024-11-25T00:10:43.804189Z",
     "shell.execute_reply": "2024-11-25T00:10:43.802208Z",
     "shell.execute_reply.started": "2024-11-25T00:10:43.779131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n",
    "  \"\"\"\n",
    "  Apply digital butterworth filter\n",
    "  INPUT\n",
    "  ------\n",
    "  1. X: (D array)\n",
    "    array with signals.\n",
    "  2. N: (int+)\n",
    "    The order of the filter.\n",
    "  3. Wn: (float+ or 1D array)\n",
    "    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n",
    "    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n",
    "    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n",
    "  4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n",
    "    The type of filter\n",
    "  5. fs: (float+)\n",
    "    The sampling frequency of the digital system.\n",
    "  6. axis: (int), Default=1.\n",
    "    The axis of x to which the filter is applied.\n",
    "  7. padtype: (str) or None, {'odd', 'even', 'constant'}\n",
    "    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n",
    "  8. padlen: (int+) or None, Default=0\n",
    "    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n",
    "  9. method: (str), {'pad', 'gust'}\n",
    "    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n",
    "    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n",
    "  10. irlen: (int) or None, Default=nONE\n",
    "    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n",
    "    For a long signal, specifying irlen can significantly improve the performance of the filter.\n",
    "  OUTPUT\n",
    "  ------\n",
    "  X_fil: (D array)\n",
    "    array with filtered signals.\n",
    "  \"\"\"\n",
    "  b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n",
    "  return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n",
    "\n",
    "class TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n",
    "  \"\"\"\n",
    "  Time frequency representation of EEG signals.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "    1. sfreq:  (float) Sampling frequency in Hz.\n",
    "    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n",
    "    3. vwt:    (2D array) Interest time windows. Default=None\n",
    "  Methods\n",
    "  -------\n",
    "    1. fit(X, y=None)\n",
    "    2. transform(X, y=None)\n",
    "  \"\"\"\n",
    "  def __init__(self, sfreq, f_bank=None, vwt=None):\n",
    "    self.sfreq = sfreq\n",
    "    self.f_bank = f_bank\n",
    "    self.vwt = vwt\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "  def _validation_param(self):\n",
    "    \"\"\"\n",
    "    Validate Time-Frequency characterization parameters.\n",
    "    INPUT\n",
    "    -----\n",
    "      1. self\n",
    "    ------\n",
    "      2. None\n",
    "    \"\"\"\n",
    "    if self.sfreq <= 0:\n",
    "      raise ValueError('Non negative sampling frequency is accepted')\n",
    "\n",
    "\n",
    "    if self.f_bank is None:\n",
    "      self.flag_f_bank = False\n",
    "    elif self.f_bank.ndim != 2:\n",
    "      raise ValueError('Band frequencies have to be a 2D array')\n",
    "    else:\n",
    "      self.flag_f_bank = True\n",
    "\n",
    "    if self.vwt is None:\n",
    "      self.flag_vwt = False\n",
    "    elif self.vwt.ndim != 2:\n",
    "      raise ValueError('Time windows have to be a 2D array')\n",
    "    else:\n",
    "      self.flag_vwt = True\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "  def _filter_bank(self, X):\n",
    "    \"\"\"\n",
    "    Filter bank Characterization.\n",
    "    INPUT\n",
    "    -----\n",
    "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
    "    OUTPUT\n",
    "    ------\n",
    "      1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n",
    "    \"\"\"\n",
    "    X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n",
    "    for f in np.arange(self.f_bank.shape[0]):\n",
    "      X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n",
    "    return X_f\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "  def _sliding_windows(self, X):\n",
    "    \"\"\"\n",
    "    Sliding Windows Characterization.\n",
    "    INPUT\n",
    "    -----\n",
    "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
    "    OUTPUT\n",
    "    ------\n",
    "      1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n",
    "    \"\"\"\n",
    "    window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n",
    "    X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n",
    "    for w in np.arange(self.vwt.shape[0]):\n",
    "        X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n",
    "    return X_w\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "  def fit(self, X, y=None):\n",
    "    \"\"\"\n",
    "    fit.\n",
    "    INPUT\n",
    "    -----\n",
    "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
    "      2. y: (1D array) target labels. Default=None\n",
    "    OUTPUT\n",
    "    ------\n",
    "      1. None\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "  def transform(self, X, y=None):\n",
    "    \"\"\"\n",
    "    Time frequency representation of EEG signals.\n",
    "    INPUT\n",
    "    -----\n",
    "      1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n",
    "    OUTPUT\n",
    "    ------\n",
    "      1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n",
    "    \"\"\"\n",
    "    self._validation_param()     #Validate sfreq, f_freq, vwt\n",
    "\n",
    "    #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n",
    "    if self.flag_f_bank:\n",
    "        X_f = self._filter_bank(X)\n",
    "    else:\n",
    "        X_f = X[:,:,:,np.newaxis]\n",
    "\n",
    "    if self.flag_vwt:\n",
    "      X_wf = []\n",
    "      for f in range(X_f.shape[3]):\n",
    "        X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n",
    "      X_wf = np.stack(X_wf, axis=-1)\n",
    "    else:\n",
    "      X_wf = X_f[:,:,:,np.newaxis,:]\n",
    "\n",
    "    return X_wf\n",
    "\n",
    "def kappa(y_true, y_pred):\n",
    "    if len(y_true.shape) == 1:\n",
    "        return cohen_kappa_score(y_true, np.argmax(y_pred, axis = 1))\n",
    "    else:\n",
    "        return cohen_kappa_score(np.argmax(y_true, axis = 1), np.argmax(y_pred, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:44.409720Z",
     "iopub.status.busy": "2024-11-25T00:10:44.409311Z",
     "iopub.status.idle": "2024-11-25T00:10:44.420596Z",
     "shell.execute_reply": "2024-11-25T00:10:44.419079Z",
     "shell.execute_reply.started": "2024-11-25T00:10:44.409684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def apply_along_epochs(func1d, epochs):\n",
    "    \"\"\"\"\"\"\n",
    "    epochs_ = epochs.copy()\n",
    "\n",
    "    data = np.apply_along_axis(func1d, -1, epochs_._data)\n",
    "\n",
    "    epochs_._data = data\n",
    "\n",
    "    return epochs_\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def get_best_montage(channels):\n",
    "    \"\"\"\"\"\"\n",
    "    data = {}\n",
    "    target = set([_.lower() for _ in channels])\n",
    "\n",
    "    for montage_name in mne.channels.get_builtin_montages():\n",
    "        montage = mne.channels.make_standard_montage(montage_name)\n",
    "        count = len(target.intersection(\n",
    "            set([_.lower() for _ in montage.ch_names])))\n",
    "        missings = target.difference(set([_.lower() for _ in montage.ch_names]))\n",
    "        missings_name = [channels[[_.lower() for _ in channels].index(nl)]\n",
    "                         for nl in missings]\n",
    "\n",
    "        data.setdefault('count', []).append(count)\n",
    "        data.setdefault('missings', []).append(len(missings))\n",
    "        data.setdefault('missings channels', []).append(missings_name)\n",
    "        data.setdefault('montage', []).append(montage_name)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    return df.sort_values('count', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:45.206781Z",
     "iopub.status.busy": "2024-11-25T00:10:45.206351Z",
     "iopub.status.idle": "2024-11-25T00:10:45.221494Z",
     "shell.execute_reply": "2024-11-25T00:10:45.219954Z",
     "shell.execute_reply.started": "2024-11-25T00:10:45.206746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_PAIN(db,sbj,f_bank,vwt,new_fs):\n",
    "\n",
    "    channels_names = np.array(['Fp1','Fp2',\n",
    "                      'F3','F4','C3','C4','P3','P4','O1','O2','F7','F8',\n",
    "                      'T7','T8','P7','P8','Fz','Cz','Pz','Oz',\n",
    "                      'FC1','FC2','CP1','CP2','FC5','FC6','CP5','CP6',\n",
    "                      'TP9','TP10','LE','RE','P1','P2','C1','C2',\n",
    "                      'FT9','FT10','AF3','AF4','FC3','FC4','CP3','CP4','PO3','PO4',\n",
    "                      'F5','F6','C5','C6','P5','P6','PO9','Iz','FT7','FT8',\n",
    "                      'TP7','TP8','PO7','PO8','Fpz','PO10','CPz','POz',\n",
    "                      'Ne','Ma','Ext','ECG'])\n",
    "    \n",
    "    with open('{}BMOP_Motor_S{}.pkl'.format(db,'0' + str(sbj) if sbj < 10 else sbj), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    X = data['X']  # trials, channels, time\n",
    "    y = data['y']\n",
    "    sex = data['sex'].ravel()\n",
    "    age = data['age'].ravel()\n",
    "    fs = float(data['fs'])\n",
    "    \n",
    "    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "    \n",
    "    #Read electrode positions to load the best standard montage-MNE\n",
    "    best_montages = get_best_montage(channels_names)\n",
    "    montage = best_montages.iloc[0]['montage']\n",
    "    no_channels = np.array(best_montages.iloc[0]['missings channels'])\n",
    "    channels_to_remove = np.array([np.argwhere(channels_names==no)[0] for no in no_channels])[:,0]\n",
    "\n",
    "    #Delete the missing channels the original array respecting the positions\n",
    "    channels_names = np.delete(channels_names, channels_to_remove)\n",
    "    X = np.delete(X, channels_to_remove, axis=1)\n",
    "\n",
    "    #Number channels does not match with the dimension of X, \n",
    "    #thus the last channel is discarded because it has weird amplitudes\n",
    "    X = X[:,:-1,:]\n",
    "\n",
    "    info = mne.create_info(list(channels_names), sfreq=fs, ch_types=\"eeg\")\n",
    "    info.set_montage(montage)\n",
    "    info\n",
    "\n",
    "    event_id = {\n",
    "        'pain/high':2,\n",
    "        'resting':3,\n",
    "        }\n",
    "\n",
    "    events = [[i, 1, cls[0]] for i, cls in enumerate(y)]\n",
    "    tmin = 0\n",
    "    \n",
    "    epochs = mne.EpochsArray(X, info, events=events, tmin=tmin, event_id=event_id)\n",
    "    X = epochs.get_data()\n",
    "    y = y-2\n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "                             \n",
    "    #Resampling\n",
    "    if new_fs != fs:\n",
    "        # print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
    "        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "    return X,y,age,sex,fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:10:59.951870Z",
     "iopub.status.busy": "2024-11-25T00:10:59.951378Z",
     "iopub.status.idle": "2024-11-25T00:10:59.958151Z",
     "shell.execute_reply": "2024-11-25T00:10:59.956870Z",
     "shell.execute_reply.started": "2024-11-25T00:10:59.951827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "seed=23\n",
    "folds=5\n",
    "epochs_train = 500\n",
    "\n",
    "data_set='PAIN'\n",
    "\n",
    "model_name = f'GFC'\n",
    "\n",
    "save_folder = os.path.join('CSP_Loso', 'CSP_Loso')\n",
    "\n",
    "n_subjects = 51\n",
    "\n",
    "PATH = f'{os. getcwd()}/{save_folder}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:11:03.657342Z",
     "iopub.status.busy": "2024-11-25T00:11:03.656902Z",
     "iopub.status.idle": "2024-11-25T00:11:03.665358Z",
     "shell.execute_reply": "2024-11-25T00:11:03.663843Z",
     "shell.execute_reply.started": "2024-11-25T00:11:03.657302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f_frec =  np.array([[4,8],[8,13],[13,32],[30,60]])\n",
    "\n",
    "tau =  2\n",
    "overlap=1-0.5\n",
    "ti = 0.5\n",
    "tf_ = 2.5\n",
    "tti = np.arange(ti,tf_-tau+(tau*overlap),tau*overlap)\n",
    "ttf = np.arange(ti+tau,tf_+tau*overlap,tau*overlap)\n",
    "vtw = np.array([tti,ttf]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:11:59.732936Z",
     "iopub.status.busy": "2024-11-25T00:11:59.732527Z",
     "iopub.status.idle": "2024-11-25T00:11:59.739296Z",
     "shell.execute_reply": "2024-11-25T00:11:59.737409Z",
     "shell.execute_reply.started": "2024-11-25T00:11:59.732902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_details = {'Females': {'Subjects': [1., 10., 12., 23., 29., 46.]}, 'Males': {'Subjects': [15., 19., 21., 25., 27.]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T00:12:18.527687Z",
     "iopub.status.busy": "2024-11-25T00:12:18.527249Z",
     "iopub.status.idle": "2024-11-25T00:14:01.174798Z",
     "shell.execute_reply": "2024-11-25T00:14:01.173594Z",
     "shell.execute_reply.started": "2024-11-25T00:12:18.527649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "Loading subject: 1\n",
      "\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "\n",
      "\n",
      "Loading subject: 10\n",
      "\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "\n",
      "\n",
      "Loading subject: 12\n",
      "\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "\n",
      "\n",
      "Loading subject: 23\n",
      "\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "\n",
      "\n",
      "Loading subject: 29\n",
      "\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "\n",
      "\n",
      "Loading subject: 46\n",
      "\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "\n",
      "\n",
      "Acc: 63.75\n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "Loading subject: 15\n",
      "\n",
      "\n",
      "\n",
      "Loading subject: 19\n",
      "\n",
      "\n",
      "\n",
      "Loading subject: 21\n",
      "\n",
      "\n",
      "\n",
      "Loading subject: 25\n",
      "\n",
      "\n",
      "\n",
      "Loading subject: 27\n",
      "\n",
      "\n",
      "\n",
      "Acc: 59.7632\n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "subjects = np.arange(n_subjects)+1\n",
    "\n",
    "db = '../input/brain-mediators-of-pain-motor/'\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "load_args = dict(db = db,\n",
    "            f_bank = np.asarray([[4., 60.]]),\n",
    "            vwt = np.asarray([[0.5,2.5]]),\n",
    "            new_fs = 500.0)\n",
    "\n",
    "genders = list(training_details.keys())\n",
    "\n",
    "print(\"Starting experiment...\\n\")\n",
    "\n",
    "for gender in genders:\n",
    "    gender_subs = training_details[gender][\"Subjects\"]\n",
    "    training_details[gender][\"Groups\"] = [] \n",
    "    g = 0\n",
    "    \n",
    "    for sbj in gender_subs:\n",
    "        print(f\"Loading subject: {int(sbj)}\\n\")\n",
    "        load_args['sbj'] = int(sbj) \n",
    "\n",
    "        if (sbj == gender_subs[0]):\n",
    "            X_train, Y_train, _, sex, _ = load_PAIN(**load_args)\n",
    "            g+=1\n",
    "            training_details[gender][\"Groups\"] += [g] * len(X_train)\n",
    "        else:\n",
    "            X_train_, Y_train_, _, sex, _ = load_PAIN(**load_args)\n",
    "            X_train = np.concatenate((X_train, X_train_), axis = 0)\n",
    "            Y_train = np.concatenate((Y_train, Y_train_), axis = 0)\n",
    "            \n",
    "            g+=1\n",
    "            training_details[gender][\"Groups\"] += [g] * len(X_train_)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    Y_train = np.array([y[0] for y in Y_train])\n",
    "\n",
    "    # ---CSP\n",
    "    steps=[('CSP_window_time',Window_band_CSP_eppoch(fs=128., vtw=vtw, f_frec=f_frec)),\n",
    "            ('flat',flatt()),\n",
    "            ('stand',StandardScaler()),\n",
    "            ('proy',elastic_net_feats()),\n",
    "            ('cla', LDA())]\n",
    "\n",
    "    method = Pipeline(steps, memory='/kaggle/tmp/datospipeline')\n",
    "\n",
    "    parameters ={'CSP_window_time__ncomp':[6],\n",
    "                 'proy__alpha':[0, 0.001, 0.1, 1], #0, 0.001, 0.1, 1\n",
    "                 'proy__l1_ratio':[0, 0.5, 1]}\n",
    "\n",
    "    scores = {'acc': 'accuracy',\n",
    "              'kappa': make_scorer(cohen_kappa_score, greater_is_better=True),\n",
    "              'auc': make_scorer(roc_auc_score, greater_is_better=True)}\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    grid_search = GridSearchCV(method, parameters, cv=logo, verbose=0,\n",
    "                               scoring=scores, refit='acc', n_jobs=1)\n",
    "\n",
    "    grid_search.fit(X = X_train, y = Y_train, groups = training_details[gender][\"Groups\"])\n",
    "\n",
    "    grid_search.cv_results_['best_index_'] = grid_search.best_index_\n",
    "\n",
    "    full_path = os.path.join(os.getcwd(), f'FBCSPMotorLosoGender', gender)\n",
    "\n",
    "    try:\n",
    "        os.makedirs(full_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    with open(full_path + f'/FBCSP_{gender}.p','wb') as f:\n",
    "        pickle.dump(grid_search.cv_results_, f)     \n",
    "    \n",
    "    print(f'Acc: {np.round(grid_search.best_score_*100,4)}')\n",
    "    \n",
    "    # ---CSP\n",
    "    print('-------------------------------------------------------------\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3008205,
     "sourceId": 5175158,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4722020,
     "sourceId": 8014908,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
