{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing libraries and libcudnn8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:13:06.194587Z",
     "iopub.status.busy": "2024-12-19T04:13:06.193857Z",
     "iopub.status.idle": "2024-12-19T04:15:25.483667Z",
     "shell.execute_reply": "2024-12-19T04:15:25.482161Z",
     "shell.execute_reply.started": "2024-12-19T04:13:06.194417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILEID = \"1h4FWB5fw7sBDCSM-EENK1UadqKSCqg24\"\n",
    "\n",
    "contents = os.listdir(os.getcwd())\n",
    "\n",
    "if 'MI_EEG_ClassMeth' not in contents:\n",
    "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n",
    "    !unzip MI_EEG_ClassMeth.zip\n",
    "else:\n",
    "    print(\"MI_EEG_ClassMeth already downloaded!\")\n",
    "\n",
    "!apt-get install --allow-change-held-packages libcudnn8=8.1.1.33-1+cuda11.2 -y\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases\n",
    "!pip install mne\n",
    "!pip install pickle5\n",
    "!pip install gcpds.utils\n",
    "!pip install scikeras[tensorflow]\n",
    "!pip install tf_keras_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weigths and Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:16:55.326377Z",
     "iopub.status.busy": "2024-12-19T04:16:55.325922Z",
     "iopub.status.idle": "2024-12-19T04:16:55.336087Z",
     "shell.execute_reply": "2024-12-19T04:16:55.334502Z",
     "shell.execute_reply.started": "2024-12-19T04:16:55.326339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FILEID = \"1sCzHf_1XFS-28wlxE9qSib1qJIy4CZ3k\"\n",
    "\n",
    "contents = os.listdir(os.getcwd())\n",
    "\n",
    "if 'GFC_Motor_500_l1l2_6gs.zip' not in contents:\n",
    "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O GFC_Motor_500_l1l2_6gs.zip && rm -rf /tmp/cookies.txt\n",
    "    !unzip GFC_Motor_500_l1l2_6gs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005353,
     "end_time": "2022-10-22T21:59:26.046417",
     "exception": false,
     "start_time": "2022-10-22T21:59:26.041064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:04.651658Z",
     "iopub.status.busy": "2024-12-19T04:17:04.651249Z",
     "iopub.status.idle": "2024-12-19T04:17:14.450996Z",
     "shell.execute_reply": "2024-12-19T04:17:14.449768Z",
     "shell.execute_reply.started": "2024-12-19T04:17:04.651619Z"
    },
    "papermill": {
     "duration": 10.438951,
     "end_time": "2022-10-22T22:02:26.565555",
     "exception": false,
     "start_time": "2022-10-22T22:02:16.126604",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# freq filter \n",
    "from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n",
    "\n",
    "#EEG montage\n",
    "from gcpds.utils.mne_handler import get_best_montage\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import pickle5 as pickle\n",
    "import warnings\n",
    "import mne\n",
    "from time import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# tensorlfow \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, AveragePooling2D, BatchNormalization, Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:17.661976Z",
     "iopub.status.busy": "2024-12-19T04:17:17.661551Z",
     "iopub.status.idle": "2024-12-19T04:17:17.668120Z",
     "shell.execute_reply": "2024-12-19T04:17:17.666672Z",
     "shell.execute_reply.started": "2024-12-19T04:17:17.661931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(np.argmax(y_true, axis = 1),np.argmax(y_pred, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:18.794498Z",
     "iopub.status.busy": "2024-12-19T04:17:18.794125Z",
     "iopub.status.idle": "2024-12-19T04:17:18.801216Z",
     "shell.execute_reply": "2024-12-19T04:17:18.799776Z",
     "shell.execute_reply.started": "2024-12-19T04:17:18.794468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def multi_sort(*args, reverse=True):\n",
    "    sorted_lists = (list(t) for t in zip(*sorted(zip(*args), reverse=reverse)))\n",
    "    return tuple(sorted_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:19.617327Z",
     "iopub.status.busy": "2024-12-19T04:17:19.616961Z",
     "iopub.status.idle": "2024-12-19T04:17:19.624541Z",
     "shell.execute_reply": "2024-12-19T04:17:19.623123Z",
     "shell.execute_reply.started": "2024-12-19T04:17:19.617299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ks_connetivity_cal(A,y):\n",
    "    D=A.shape[-1]\n",
    "    ks = np.zeros(D)\n",
    "    pvalue = np.zeros(D)\n",
    "    for d in range(D):\n",
    "        ks[d],pvalue[d]=ks_2samp(A[y==0, d], A[y==1, d], alternative = 'two-side', mode = 'auto')\n",
    "    return ks,pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:22.131578Z",
     "iopub.status.busy": "2024-12-19T04:17:22.131164Z",
     "iopub.status.idle": "2024-12-19T04:17:22.147850Z",
     "shell.execute_reply": "2024-12-19T04:17:22.146268Z",
     "shell.execute_reply.started": "2024-12-19T04:17:22.131546Z"
    },
    "papermill": {
     "duration": 2.730715,
     "end_time": "2022-10-22T22:02:29.329591",
     "exception": false,
     "start_time": "2022-10-22T22:02:26.598876",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_PAIN(db,sbj,f_bank,vwt,new_fs):\n",
    "\n",
    "    channels_names = np.array(['Fp1','Fp2',\n",
    "                      'F3','F4','C3','C4','P3','P4','O1','O2','F7','F8',\n",
    "                      'T7','T8','P7','P8','Fz','Cz','Pz','Oz',\n",
    "                      'FC1','FC2','CP1','CP2','FC5','FC6','CP5','CP6',\n",
    "                      'TP9','TP10','LE','RE','P1','P2','C1','C2',\n",
    "                      'FT9','FT10','AF3','AF4','FC3','FC4','CP3','CP4','PO3','PO4',\n",
    "                      'F5','F6','C5','C6','P5','P6','PO9','Iz','FT7','FT8',\n",
    "                      'TP7','TP8','PO7','PO8','Fpz','PO10','CPz','POz',\n",
    "                      'Ne','Ma','Ext','ECG'])\n",
    "    \n",
    "    with open('{}BMOP_Motor_S{}.pkl'.format(db,'0' + str(sbj) if sbj < 10 else sbj), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    X = data['X']  # trials, channels, time\n",
    "    y = data['y']\n",
    "    sex = data['sex'].ravel()\n",
    "    age = data['age'].ravel()\n",
    "    fs = float(data['fs'])\n",
    "    \n",
    "    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "    \n",
    "    #Read electrode positions to load the best standard montage-MNE\n",
    "    best_montages = get_best_montage(channels_names)\n",
    "    montage = best_montages.iloc[0]['montage']\n",
    "    no_channels = np.array(best_montages.iloc[0]['missings channels'])\n",
    "    channels_to_remove = np.array([np.argwhere(channels_names==no)[0] for no in no_channels])[:,0]\n",
    "\n",
    "    #Delete the missing channels the original array respecting the positions\n",
    "    channels_names = np.delete(channels_names, channels_to_remove)\n",
    "    X = np.delete(X, channels_to_remove, axis=1)\n",
    "\n",
    "    #Number channels does not match with the dimension of X, \n",
    "    #thus the last channel is discarded because it has weird amplitudes\n",
    "    X = X[:,:-1,:]\n",
    "\n",
    "    info = mne.create_info(list(channels_names), sfreq=fs, ch_types=\"eeg\")\n",
    "    info.set_montage(montage)\n",
    "    info\n",
    "\n",
    "    event_id = {\n",
    "        'pain/high':2,\n",
    "        'resting':3,\n",
    "        }\n",
    "\n",
    "    events = [[i, 1, cls[0]] for i, cls in enumerate(y)]\n",
    "    tmin = 0\n",
    "\n",
    "    epochs = mne.EpochsArray(X, info, events=events, tmin=tmin, event_id=event_id)\n",
    "    X = epochs.get_data()\n",
    "    y = y-2\n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "                             \n",
    "    #Resampling\n",
    "    if new_fs != fs:\n",
    "        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "        \n",
    "    return X,y,age,sex,fs,info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model (Gaussian functional conectivity network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:26.935560Z",
     "iopub.status.busy": "2024-12-19T04:17:26.935190Z",
     "iopub.status.idle": "2024-12-19T04:17:26.959360Z",
     "shell.execute_reply": "2024-12-19T04:17:26.958180Z",
     "shell.execute_reply.started": "2024-12-19T04:17:26.935528Z"
    },
    "papermill": {
     "duration": 4.643402,
     "end_time": "2022-10-22T22:02:34.006275",
     "exception": false,
     "start_time": "2022-10-22T22:02:29.362873",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GFC(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.gammad = self.add_weight(name = 'gammad',\n",
    "                                shape = (),\n",
    "                                initializer = 'zeros',\n",
    "                                trainable = True)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X): \n",
    "        X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n",
    "        R = tf.reduce_sum(tf.math.multiply(X, X), axis = -1, keepdims = True) #(N, F, C, 1)\n",
    "        D  = R - 2*tf.matmul(X, X, transpose_b = True) + tf.transpose(R, perm = (0, 1, 3, 2)) #(N, F, C, C)\n",
    "\n",
    "        ones = tf.ones_like(D[0,0,...]) #(C, C)\n",
    "        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n",
    "        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n",
    "        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n",
    "        triu = tf.expand_dims(tf.boolean_mask(D, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n",
    "        sigma = tfp.stats.percentile(tf.math.sqrt(triu), 50, axis = 2, keepdims = True) #(N, F, 1, 1)\n",
    "\n",
    "        A = tf.math.exp(-1/(2*tf.pow(10., self.gammad)*tf.math.square(sigma))*D) #(N, F, C, C)\n",
    "        A.set_shape(D.shape)\n",
    "        return A\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        N, C, T, F = batch_input_shape.as_list()\n",
    "        return tf.TensorShape([N, F, C, C])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "\n",
    "\n",
    "class get_triu(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X): \n",
    "        N, F, C, C = X.shape\n",
    "        ones = tf.ones_like(X[0,0,...]) #(C, C)\n",
    "        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n",
    "        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n",
    "        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n",
    "        triu = tf.expand_dims(tf.boolean_mask(X, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n",
    "\n",
    "        triu.set_shape([N,F,int(C*(C-1)/2),1])\n",
    "        return triu\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        N, F, C, C = batch_input_shape.as_list()\n",
    "        return tf.TensorShape([N, F, int(C*(C-1)/2),1])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "    \n",
    "    \n",
    "def GFC_triu_net_avg(nb_classes: int,\n",
    "          Chans: int,\n",
    "          Samples: int,\n",
    "          l1: int = 0, \n",
    "          l2: int = 0, \n",
    "          dropoutRate: float = 0.5,\n",
    "          filters: int = 1, \n",
    "          maxnorm: float = 2.0,\n",
    "          maxnorm_last_layer: float = 0.5,\n",
    "          kernel_time_1: int = 20,\n",
    "          strid_filter_time_1: int = 1,\n",
    "          bias_spatial: bool = False) -> Model:\n",
    "\n",
    "\n",
    "    input_main   = Input((Chans, Samples, 1),name='Input')                    \n",
    "    \n",
    "    block        = Conv2D(filters,(1,kernel_time_1),strides=(1,strid_filter_time_1),\n",
    "                            use_bias=bias_spatial, name='Conv2D_1',\n",
    "                            kernel_constraint = max_norm(maxnorm, axis=(0,1,2))\n",
    "                            )(input_main)\n",
    "    \n",
    "    block        = BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n",
    "\n",
    "    block        = Activation('elu')(block)      \n",
    "    \n",
    "    block        = GFC(name=\"gfc\")(block)\n",
    "\n",
    "    block        = get_triu()(block)\n",
    "\n",
    "    block        = AveragePooling2D(pool_size=(block.shape[1],1),strides=(1,1))(block)\n",
    "    \n",
    "    block        = BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n",
    "\n",
    "    block        = Activation('elu')(block) \n",
    "    \n",
    "    block        = Flatten(name='fc')(block)    \n",
    "\n",
    "    block        = Dropout(dropoutRate)(block) \n",
    "\n",
    "    block        = Dense(nb_classes, kernel_regularizer=L1L2(l1=l1,l2=l2),name='logits',\n",
    "                              kernel_constraint = max_norm(maxnorm_last_layer)\n",
    "                              )(block)\n",
    "\n",
    "    softmax      = Activation('softmax',name='output')(block)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:28.596324Z",
     "iopub.status.busy": "2024-12-19T04:17:28.595935Z",
     "iopub.status.idle": "2024-12-19T04:17:28.611154Z",
     "shell.execute_reply": "2024-12-19T04:17:28.609490Z",
     "shell.execute_reply.started": "2024-12-19T04:17:28.596293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "def EEGNet(nb_classes, Chans = 64, Samples = 128,\n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8,\n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   name='Conv2D_1',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n",
    "                                   name='Depth_wise_Conv2D_1',\n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   name='Separable_Conv2D_1',\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "\n",
    "    dense        = Dense(nb_classes, name = 'output',\n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'out_activation')(dense)\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T22:02:34.07466Z",
     "iopub.status.busy": "2022-10-22T22:02:34.074032Z",
     "iopub.status.idle": "2022-10-22T22:02:34.086988Z",
     "shell.execute_reply": "2022-10-22T22:02:34.086008Z"
    },
    "papermill": {
     "duration": 0.049558,
     "end_time": "2022-10-22T22:02:34.089324",
     "exception": false,
     "start_time": "2022-10-22T22:02:34.039766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:31.522297Z",
     "iopub.status.busy": "2024-12-19T04:17:31.521881Z",
     "iopub.status.idle": "2024-12-19T04:17:31.528091Z",
     "shell.execute_reply": "2024-12-19T04:17:31.526552Z",
     "shell.execute_reply.started": "2024-12-19T04:17:31.522264Z"
    },
    "papermill": {
     "duration": 0.048584,
     "end_time": "2022-10-22T22:02:34.171415",
     "exception": false,
     "start_time": "2022-10-22T22:02:34.122831",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed = 23\n",
    "n_subjects = 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T22:02:35.565905Z",
     "iopub.status.busy": "2022-10-22T22:02:35.565531Z",
     "iopub.status.idle": "2022-10-22T22:02:35.582215Z",
     "shell.execute_reply": "2022-10-22T22:02:35.581284Z"
    },
    "papermill": {
     "duration": 0.051828,
     "end_time": "2022-10-22T22:02:35.58406",
     "exception": false,
     "start_time": "2022-10-22T22:02:35.532232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:35.840792Z",
     "iopub.status.busy": "2024-12-19T04:17:35.840378Z",
     "iopub.status.idle": "2024-12-19T04:17:49.670995Z",
     "shell.execute_reply": "2024-12-19T04:17:49.669483Z",
     "shell.execute_reply.started": "2024-12-19T04:17:35.840755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n",
    "\n",
    "from gcpds.visualizations.topoplots import topoplot\n",
    "from gcpds.visualizations.connectivities import CircosConnectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-19T04:17:53.958779Z",
     "iopub.status.busy": "2024-12-19T04:17:53.958350Z",
     "iopub.status.idle": "2024-12-19T04:18:17.515883Z",
     "shell.execute_reply": "2024-12-19T04:18:17.514384Z",
     "shell.execute_reply.started": "2024-12-19T04:17:53.958734Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed)\n",
    "\n",
    "subjects = np.arange(n_subjects)+1\n",
    "\n",
    "db = '../input/brain-mediators-of-pain-motor/'\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "load_args = dict(db = db,\n",
    "            f_bank = np.asarray([[4., 60.]]),\n",
    "            vwt = np.asarray([[0.5,2.5]]),\n",
    "            new_fs = 500.0)\n",
    "\n",
    "for sbj in [1]:\n",
    "    print(f\"\\nSubject: {sbj}\")\n",
    "    \n",
    "    load_args['sbj'] = sbj\n",
    "\n",
    "    X_train, y_train, age, sex, fs, _ = load_PAIN(**load_args)\n",
    "\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    Y_train = tf.keras.utils.to_categorical(y_train,num_classes=num_class)\n",
    "    y_train = np.array([y[0] for y in y_train])\n",
    "\n",
    "full_path = os.path.join(os.getcwd())\n",
    "\n",
    "gfcnet_scores = np.zeros((len(subjects)-1,8))\n",
    "\n",
    "C = X_train.shape[1]\n",
    "ks = np.zeros((1, int(C*(C-1)/2)))\n",
    "pvalue = np.zeros((1, int(C*(C-1)/2)))\n",
    "\n",
    "Nfilters_ = np.zeros((len(subjects) - 1))\n",
    "kernel_time_ = np.zeros((len(subjects) - 1))\n",
    "\n",
    "i = 0\n",
    "\n",
    "sbjs_info = []\n",
    "acc_comp = []\n",
    "\n",
    "gfc_scores_256_path = os.path.join(os.getcwd(), 'GFC_Motor_256_Gamma60Hz')\n",
    "\n",
    "for sbj in subjects:\n",
    "    if sbj == 18:\n",
    "        continue\n",
    "        \n",
    "    load_args['sbj'] = sbj\n",
    "    X_train, y_train, age, sex, fs, _ = load_PAIN(**load_args)\n",
    "    y_train = np.array([y[0] for y in y_train])\n",
    "\n",
    "    sbjInfo = {}\n",
    "    sbjInfo[\"Subject\"] = sbj\n",
    "\n",
    "    with open(os.path.join(gfc_scores_256_path, f'Subject{sbj}.p'), 'rb') as f:\n",
    "        cv = pickle.load(f)\n",
    "        \n",
    "    acc_comp.append((cv['mean_test_Accuracy'][cv['best_index_']], sbj, sex[0]))\n",
    "\n",
    "ordScores = multi_sort(acc_comp)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T04:19:06.026684Z",
     "iopub.status.busy": "2024-11-12T04:19:06.026293Z",
     "iopub.status.idle": "2024-11-12T04:19:06.033359Z",
     "shell.execute_reply": "2024-11-12T04:19:06.032381Z",
     "shell.execute_reply.started": "2024-11-12T04:19:06.026652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_subs = [score[1] for score in ordScores[:3]]\n",
    "mid_subs = [score[1] for score in ordScores[int(len(ordScores) / 2) - 1: int(len(ordScores) / 2) + 2]]\n",
    "worst_subs = [score[1] for score in ordScores[-3:]]\n",
    "\n",
    "subs_to_analyze = {'Good': best_subs, 'Mean': mid_subs, 'Bad': worst_subs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate for FS = 500 Hz and Freq Bank = [4, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:23:57.912777Z",
     "iopub.status.busy": "2024-12-19T04:23:57.911775Z",
     "iopub.status.idle": "2024-12-19T04:23:57.923202Z",
     "shell.execute_reply": "2024-12-19T04:23:57.919292Z",
     "shell.execute_reply.started": "2024-12-19T04:23:57.912645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for content in os.listdir():\n",
    "    if '.png' in content or '.pdf' in content:\n",
    "        os.remove(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T04:24:02.247005Z",
     "iopub.status.busy": "2024-12-19T04:24:02.245687Z",
     "iopub.status.idle": "2024-12-19T04:24:14.257862Z",
     "shell.execute_reply": "2024-12-19T04:24:14.256554Z",
     "shell.execute_reply.started": "2024-12-19T04:24:02.246944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_keras_vis import gradcam_plus_plus\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "subjects = np.arange(n_subjects)+1\n",
    "\n",
    "db = '../input/brain-mediators-of-pain-motor/'\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "load_args = dict(db = db,\n",
    "            f_bank = np.asarray([[4., 60.]]),\n",
    "            vwt = np.asarray([[0.5,2.5]]),\n",
    "            new_fs = 500.0)\n",
    "\n",
    "scores_path = os.path.join(os.getcwd(), 'GFC_Motor_500_l1l2_6gs')\n",
    "\n",
    "# [15, 19, 21, 25, 27]\n",
    "# [1, 10, 12, 23, 29, 46]\n",
    "for sbj in [15, 19, 21, 25, 27]:\n",
    "    if sbj == 18:\n",
    "        continue\n",
    "\n",
    "    load_args['sbj'] = sbj\n",
    "\n",
    "    X_train, y_train, age, sex, fs, info = load_PAIN(**load_args)\n",
    "\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    Y_train = tf.keras.utils.to_categorical(y_train,num_classes=num_class)\n",
    "    y_train = np.array([y[0] for y in y_train])\n",
    "\n",
    "    channels = info['ch_names']\n",
    "\n",
    "    model_weights_path = os.path.join(scores_path, f\"Subject{sbj}_weights.h5\")\n",
    "    params_path = os.path.join(scores_path, f\"Subject{sbj}.p\")\n",
    "\n",
    "    with open(params_path, 'rb') as f:\n",
    "        cv = pickle.load(f)\n",
    "\n",
    "    nFilters_ = cv['params'][cv['best_index_']]['filters']\n",
    "    kernel_time_ = cv['params'][cv['best_index_']]['kernel_time_1']\n",
    "\n",
    "    model = GFC_triu_net_avg(nb_classes = num_class,\n",
    "            Chans = X_train.shape[1],\n",
    "            Samples = X_train.shape[2],\n",
    "            filters = int(nFilters_), \n",
    "            kernel_time_1 =int(kernel_time_))\n",
    "\n",
    "    model.load_weights(model_weights_path)\n",
    "\n",
    "    pain_scores = [CategoricalScore(list(np.zeros_like(y_train)))]\n",
    "    rest_scores = [CategoricalScore(list(np.ones_like(y_train)))]\n",
    "\n",
    "    no_softmax_model = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "    \n",
    "    lc = gradcam_plus_plus.GradcamPlusPlus(model, model_modifier=ReplaceToLinear(), clone=False)\n",
    "\n",
    "    Penultimate_layer = model.layers[-2]\n",
    "\n",
    "    pain_cam = lc(score = pain_scores,\n",
    "                  seed_input = X_train,\n",
    "                  penultimate_layer = Penultimate_layer,\n",
    "                  seek_penultimate_conv_layer = True,\n",
    "                  normalize_cam = False,\n",
    "                  expand_cam = True)\n",
    "\n",
    "    rest_cam = lc(score = rest_scores,\n",
    "                  seed_input = X_train,\n",
    "                  penultimate_layer = Penultimate_layer,\n",
    "                  seek_penultimate_conv_layer = True,\n",
    "                  normalize_cam = False,\n",
    "                  expand_cam = True)\n",
    "\n",
    "    max_val_cams = np.max(np.concatenate((pain_cam[...,np.newaxis],\n",
    "                                                  rest_cam[...,np.newaxis]), axis=-1), axis=(1,2,3))[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    pain_cam/=max_val_cams\n",
    "    rest_cam/=max_val_cams\n",
    "\n",
    "    pain_cam = rest_cam - pain_cam\n",
    "\n",
    "    theta_filter = TimeFrequencyRpr(sfreq = fs, f_bank = np.array([[4., 8.]]))\n",
    "    alpha_filter = TimeFrequencyRpr(sfreq = fs, f_bank = np.array([[8., 13.]]))\n",
    "    beta_filter = TimeFrequencyRpr(sfreq = fs, f_bank = np.array([[13., 32.]]))\n",
    "    gamma_filter = TimeFrequencyRpr(sfreq = fs, f_bank = np.array([[30., 60.]]))\n",
    "\n",
    "    pain_signals = np.array(X_train[y_train == 0][...,0])\n",
    "    rest_signals = np.array(X_train[y_train == 1][...,0])\n",
    "\n",
    "    ##########\n",
    "    mean_pain_signals = np.sum(np.mean(pain_signals, axis = 0), axis=1)\n",
    "    min_mps = np.min(mean_pain_signals, axis=0)\n",
    "    mean_pain_signals-=min_mps\n",
    "    max_mps = np.max(mean_pain_signals, axis=0)\n",
    "    mean_pain_signals/=max_mps\n",
    "\n",
    "    mean_pain_cams = np.sum(np.mean(pain_cam, axis = 0), axis=1)\n",
    "    min_mpc = np.min(mean_pain_cams, axis=0)\n",
    "    mean_pain_cams-=min_mpc\n",
    "    max_mpc = np.max(mean_pain_cams, axis=0)\n",
    "    mean_pain_cams/=max_mpc\n",
    "\n",
    "    mean_rest_signals = np.sum(np.mean(rest_signals, axis = 0), axis=1)\n",
    "    min_mrs = np.min(mean_rest_signals, axis=0)\n",
    "    mean_rest_signals-=min_mrs\n",
    "    max_mrs = np.max(mean_rest_signals, axis=0)\n",
    "    mean_rest_signals/=max_mrs\n",
    "\n",
    "    mean_rest_cams = np.sum(np.mean(rest_cam, axis = 0), axis=1)\n",
    "    min_mrc = np.min(mean_rest_cams, axis=0)\n",
    "    mean_rest_cams-=min_mrc\n",
    "    max_mrc = np.max(mean_rest_cams, axis=0)\n",
    "    mean_rest_cams/=max_mrc   \n",
    "    ##########\n",
    "\n",
    "    pain_signal_theta = np.sum(np.mean(theta_filter.transform(pain_signals)[...,0,0], axis = 0), axis=1)\n",
    "    pain_signal_alpha = np.sum(np.mean(alpha_filter.transform(pain_signals)[...,0,0], axis = 0), axis=1)\n",
    "    pain_signal_beta = np.sum(np.mean(beta_filter.transform(pain_signals)[...,0,0], axis = 0), axis=1)\n",
    "    pain_signal_gamma = np.sum(np.mean(gamma_filter.transform(pain_signals)[...,0,0], axis = 0), axis=1)\n",
    "    pain_min_signal = np.min(np.concatenate((pain_signal_theta, pain_signal_alpha, pain_signal_beta, pain_signal_gamma), axis=0))\n",
    "\n",
    "    pain_signal_theta -= pain_min_signal\n",
    "    pain_signal_alpha -= pain_min_signal\n",
    "    pain_signal_beta -= pain_min_signal\n",
    "    pain_signal_gamma -= pain_min_signal\n",
    "    pain_max_signal = np.max(np.concatenate((pain_signal_theta, pain_signal_alpha, pain_signal_beta, pain_signal_gamma), axis=0))     \n",
    "\n",
    "    pain_signal_theta /= pain_max_signal\n",
    "    pain_signal_alpha /= pain_max_signal\n",
    "    pain_signal_beta /= pain_max_signal\n",
    "    pain_signal_gamma /= pain_max_signal\n",
    "\n",
    "    ####\n",
    "    rest_signal_theta = np.sum(np.mean(theta_filter.transform(rest_signals)[...,0,0], axis = 0), axis=1)\n",
    "    rest_signal_alpha = np.sum(np.mean(alpha_filter.transform(rest_signals)[...,0,0], axis = 0), axis=1)\n",
    "    rest_signal_beta = np.sum(np.mean(beta_filter.transform(rest_signals)[...,0,0], axis = 0), axis=1)\n",
    "    rest_signal_gamma = np.sum(np.mean(gamma_filter.transform(rest_signals)[...,0,0], axis = 0), axis=1)\n",
    "    rest_min_signal = np.min(np.concatenate((rest_signal_theta, rest_signal_alpha, rest_signal_beta, rest_signal_gamma), axis=0))\n",
    "\n",
    "    rest_signal_theta -= rest_min_signal\n",
    "    rest_signal_alpha -= rest_min_signal\n",
    "    rest_signal_beta -= rest_min_signal\n",
    "    rest_signal_gamma -= rest_min_signal\n",
    "    rest_max_signal = np.max(np.concatenate((rest_signal_theta, rest_signal_alpha, rest_signal_beta, rest_signal_gamma), axis=0))     \n",
    "\n",
    "    rest_signal_theta /= rest_max_signal\n",
    "    rest_signal_alpha /= rest_max_signal\n",
    "    rest_signal_beta /= rest_max_signal\n",
    "    rest_signal_gamma /= rest_max_signal\n",
    "    ####\n",
    "\n",
    "    pain_cam_theta = np.sum(np.mean(theta_filter.transform(pain_cam)[...,0,0], axis = 0), axis=1)\n",
    "    pain_cam_alpha = np.sum(np.mean(alpha_filter.transform(pain_cam)[...,0,0], axis = 0), axis=1)\n",
    "    pain_cam_beta = np.sum(np.mean(beta_filter.transform(pain_cam)[...,0,0], axis = 0), axis=1)\n",
    "    pain_cam_gamma = np.sum(np.mean(gamma_filter.transform(pain_cam)[...,0,0], axis = 0), axis=1)\n",
    "    pain_min_cam = np.min(np.concatenate((pain_cam_theta, pain_cam_alpha, pain_cam_beta, pain_cam_gamma), axis=0))\n",
    "\n",
    "    pain_cam_theta -= pain_min_cam\n",
    "    pain_cam_alpha -= pain_min_cam\n",
    "    pain_cam_beta -= pain_min_cam\n",
    "    pain_cam_gamma -= pain_min_cam\n",
    "    pain_max_cam = np.max(np.concatenate((pain_cam_theta, pain_cam_alpha, pain_cam_beta, pain_cam_gamma), axis=0))\n",
    "\n",
    "    pain_cam_theta /= pain_max_cam\n",
    "    pain_cam_alpha /= pain_max_cam\n",
    "    pain_cam_beta /= pain_max_cam\n",
    "    pain_cam_gamma /= pain_max_cam\n",
    "\n",
    "    ####\n",
    "    rest_cam_theta = np.sum(np.mean(theta_filter.transform(rest_cam)[...,0,0], axis = 0), axis=1)\n",
    "    rest_cam_alpha = np.sum(np.mean(alpha_filter.transform(rest_cam)[...,0,0], axis = 0), axis=1)\n",
    "    rest_cam_beta = np.sum(np.mean(beta_filter.transform(rest_cam)[...,0,0], axis = 0), axis=1)\n",
    "    rest_cam_gamma = np.sum(np.mean(gamma_filter.transform(rest_cam)[...,0,0], axis = 0), axis=1)\n",
    "    rest_min_cam = np.min(np.concatenate((rest_cam_theta, rest_cam_alpha, rest_cam_beta, rest_cam_gamma), axis=0))\n",
    "\n",
    "    rest_cam_theta -= rest_min_cam\n",
    "    rest_cam_alpha -= rest_min_cam\n",
    "    rest_cam_beta -= rest_min_cam\n",
    "    rest_cam_gamma -= rest_min_cam\n",
    "    rest_max_cam = np.max(np.concatenate((rest_cam_theta, rest_cam_alpha, rest_cam_beta), axis=0))\n",
    "\n",
    "    rest_cam_theta /= rest_max_cam\n",
    "    rest_cam_alpha /= rest_max_cam\n",
    "    rest_cam_beta /= rest_max_cam\n",
    "    rest_cam_gamma /= rest_max_cam\n",
    "    ####\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic([['ll', 'lm', 'lm1', 'lm2', 'lr'], ['bl', 'bm', 'bm1', 'bm2', 'br']], figsize=(14, 6))\n",
    "    \n",
    "    im_00 = topoplot(pain_cam_theta, channels, cmap='viridis', ax=ax['ll'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(pain_cam_alpha, channels, cmap='viridis', ax=ax['lm'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(pain_cam_beta, channels, cmap='viridis', ax=ax['lm1'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(pain_cam_gamma, channels, cmap='viridis', ax=ax['lm2'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(mean_pain_cams, channels, cmap='viridis', ax=ax['lr'], vlim=(0.0, 1.0), show=False)\n",
    "\n",
    "    topoplot(rest_cam_theta, channels, cmap='viridis', ax=ax['bl'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(rest_cam_alpha, channels, cmap='viridis', ax=ax['bm'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(rest_cam_beta, channels, cmap='viridis', ax=ax['bm1'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(rest_cam_gamma, channels, cmap='viridis', ax=ax['bm2'], vlim=(0.0, 1.0), show=False)\n",
    "    topoplot(mean_rest_cams, channels, cmap='viridis', ax=ax['br'], vlim=(0.0, 1.0), show=False)\n",
    "\n",
    "    ax['ll'].set_ylabel(f'CAMs Pain', size=20)\n",
    "    ax['bl'].set_ylabel(f'CAMs Rest', size=20)\n",
    "    ax['ll'].set_title(f'Theta', size=20)\n",
    "    ax['lm'].set_title(f'Alpha', size=20)\n",
    "    ax['lm1'].set_title(f'Beta', size=20)\n",
    "    ax['lm2'].set_title(f'Gamma', size=20)\n",
    "    ax['lr'].set_title(f'Full Band', size=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(right=0.75)\n",
    "    cbar_ax = fig.add_axes([0.8, 0.3, 0.02, 0.5])\n",
    "    fig.colorbar(im_00[0], cax=cbar_ax)\n",
    "    plt.savefig(f'Subject{sbj}Cams.pdf', format='pdf', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:27:53.117932Z",
     "iopub.status.busy": "2024-11-25T14:27:53.117247Z",
     "iopub.status.idle": "2024-11-25T14:27:53.129179Z",
     "shell.execute_reply": "2024-11-25T14:27:53.127710Z",
     "shell.execute_reply.started": "2024-11-25T14:27:53.117872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "areas = { ## mine\n",
    "    'Frontal': ['Fpz', 'Fz'],\n",
    "    'Frontal Right': ['Fp2','AF4','F4','F6','F8',],\n",
    "    'Central Right': ['FC2','FC4','FC6','FT8', 'FT10', 'C2','C4','C6','T8','CP2','CP4','CP6','TP8', 'TP10'],\n",
    "    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2', 'PO10'],\n",
    "    # 'Central': ['Cz'],\n",
    "    'Posterior': ['Cz', 'CPz','Pz', 'POz', 'Oz','Iz',],\n",
    "    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1', 'PO9'],\n",
    "    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7', 'FT9', 'TP9'],\n",
    "    'Frontal Left': ['Fp1','AF3', 'F3', 'F5', 'F7',],\n",
    "}\n",
    "\n",
    "arcs = ['areas', 'channels']\n",
    "\n",
    "areas_cmap='Set3'\n",
    "arcs_cmap='Purples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:31:09.503791Z",
     "iopub.status.busy": "2024-11-25T14:31:09.502450Z",
     "iopub.status.idle": "2024-11-25T14:31:15.068150Z",
     "shell.execute_reply": "2024-11-25T14:31:15.066698Z",
     "shell.execute_reply.started": "2024-11-25T14:31:09.503732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "subjects = np.arange(n_subjects)+1\n",
    "\n",
    "db = '../input/brain-mediators-of-pain-motor/'\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "load_args = dict(db = db,\n",
    "            f_bank = np.asarray([[4., 60.]]),\n",
    "            vwt = np.asarray([[0.5,2.5]]),\n",
    "            new_fs = 256.0)\n",
    "\n",
    "scores_path = os.path.join(os.getcwd(), 'GFC_Motor_256_Gamma60Hz')\n",
    "\n",
    "# [15, 19, 21, 25, 27]\n",
    "# [1, 10, 12, 23, 29, 46]\n",
    "for sbj in [15, 19, 21, 25, 27]:\n",
    "    if sbj == 18:\n",
    "        continue\n",
    "\n",
    "    load_args['sbj'] = sbj\n",
    "\n",
    "    X_train, y_train, age, sex, fs, info = load_PAIN(**load_args)\n",
    "\n",
    "    y_train_ = y_train.copy()\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    Y_train = tf.keras.utils.to_categorical(y_train,num_classes=num_class)\n",
    "    y_train = np.array([y[0] for y in y_train])\n",
    "\n",
    "    channels = info['ch_names']\n",
    "\n",
    "    model_weights_path = os.path.join(scores_path, f\"Subject{sbj}_weights.h5\")\n",
    "    params_path = os.path.join(scores_path, f\"Subject{sbj}.p\")\n",
    "\n",
    "    with open(params_path, 'rb') as f:\n",
    "        cv = pickle.load(f)\n",
    "\n",
    "    nFilters_ = cv['params'][cv['best_index_']]['filters']\n",
    "    kernel_time_ = cv['params'][cv['best_index_']]['kernel_time_1']\n",
    "\n",
    "    model = GFC_triu_net_avg(nb_classes = num_class,\n",
    "            Chans = X_train.shape[1],\n",
    "            Samples = X_train.shape[2],\n",
    "            filters = int(nFilters_), \n",
    "            kernel_time_1 =int(kernel_time_))\n",
    "\n",
    "    model.load_weights(model_weights_path)\n",
    "\n",
    "    layer_name='fc'\n",
    "    fC_layer = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    fc_layer_predict = fC_layer.predict(X_train)\n",
    "\n",
    "    ks, pvalue = ks_connetivity_cal(fc_layer_predict, y_train_.reshape(-1))\n",
    "\n",
    "    mask = np.copy(fc_layer_predict)\n",
    "    mask[:,pvalue > 0.05] = 0\n",
    "    max_mask = np.max(mask, axis=0)\n",
    "    abs_vals = abs(max_mask)\n",
    "    max_val = np.max(abs_vals)\n",
    "    v = abs(max_mask / max_val)\n",
    "    plt.figure(figsize=(16,12), dpi=100)\n",
    "    ax = CircosConnectivity(v, channels=channels, areas=areas, labelsize=20, min_alpha=0.1, threshold=0.97, \n",
    "                      areas_cmap=areas_cmap, arcs_cmap=arcs_cmap, size=20, show_emisphere=False, arcs_separation=30,\n",
    "                      hemisphere_color='lightgray', channel_color='#f8f9fa', connection_width=0.2, small_separation=5, \n",
    "                      big_separation=5, offset=-1.5, vmin=0.001,vmax=1.0)\n",
    "    plt.savefig(f'Subject{sbj}_Connectivities.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1645904,
     "sourceId": 2702213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1269900,
     "sourceId": 2702226,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4722020,
     "sourceId": 8014908,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30302,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
